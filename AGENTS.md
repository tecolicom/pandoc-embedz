# Repository Guidelines

## Project Structure & Module Organization
- `pandoc_embedz/` hosts the filter implementation (`filter.py`), constants like `SAVED_TEMPLATES`, and the `pandoc-embedz` console script entry point.
- `tests/` contains the `test_*.py` suites plus `tests/fixtures/` sample data; keep new coverage next to the behavior you want to lock down.
- `examples/` stores runnable Markdown that mirrors README scenarios; use it to verify CLI changes before updating docs.
- `build/`, `dist/`, and `pandoc_embedz.egg-info/` are packaging outputs generated by `uv build` or `python -m build`; do not commit them.
- `uv.lock` is the dependency lock file for reproducible builds; commit this to version control.

## Build, Test, and Development Commands

### With uv (Recommended)
- `uv sync --all-extras` syncs dependencies and creates/updates `.venv` with dev extras
- `uv run pytest tests/` runs tests with the project `pyproject.toml` config
- `uv build` produces wheel and sdist artifacts in `dist/` for release candidates
- `uv add <package>` adds a new dependency to `pyproject.toml` and updates `uv.lock`
- `uv remove <package>` removes a dependency from `pyproject.toml` and updates `uv.lock`

### With pip (Alternative)
- `pip install -e .` links the package into your venv so changes take effect immediately
- `pip install .[dev]` installs `pytest` and other dev extras defined under `[project.optional-dependencies]`
- `python -m build` produces wheel and sdist artifacts in `dist/` for release candidates
- `python -m pytest` uses the project `pyproject.toml` config (`-v`, `--strict-markers`, `--tb=short`) and automatically targets `tests/test_*.py`

### Testing the Filter
- `pandoc report.md --filter pandoc-embedz -o report.pdf` (or `pandoc-embedz` directly) exercises the filter in a realistic pipeline

## Debug Mode
Enable detailed debug output by setting the `PANDOC_EMBEDZ_DEBUG` environment variable:

```bash
PANDOC_EMBEDZ_DEBUG=1 pandoc report.md --filter pandoc-embedz -o output.pdf
```

Accepted values: `1`, `true`, `yes` (case-insensitive)

Debug output includes:
- Configuration parsing (attributes and YAML)
- Template save/load operations
- Variable preparation (global and local)
- Data loading parameters and queries
- Template rendering context
- Processing steps for each embedz block

All debug messages are prefixed with `[DEBUG]` and written to stderr.

## Coding Style & Naming Conventions
- Keep Python code PEP 8-compliant: 4-space indentation, short helper functions (`snake_case`), and module-level constants in `CONSTANT_CASE`.
- Prefer explicit typing, docstrings, and config dictionaries similar to `parse_attributes` so intent stays clear.
- Use `pathlib.Path`, `validate_file_path`, and explicit checks every time you touch the filesystem, mirroring the existing security helpers.

## Testing Guidelines
- Tests live under `tests/` with `Test*` classes and `test_*` functions; name fixtures clearly and store shared data in `tests/fixtures/`.
- **IMPORTANT: Always run `uv run pytest tests/` (or `python -m pytest tests/`) (全テスト) before committing.** Running individual test files may miss failures in other test suites.
- Add coverage-sensitive scenarios (e.g., format detection, dot-notation parsing) as the filter evolves, and document the commands you used to validate them.

## Commit & Pull Request Guidelines
- **Before committing: Run `uv run pytest tests/` (or `python -m pytest tests/`) to ensure all tests pass.** This catches failures across all test suites.
- Follow the current git log style: start with a capitalized verb phrase, optionally separate a short summary from extra detail with a colon, and avoid terminal periods.
- PRs should target `main`, include a summary, list the commands you ran (tests, build, manual Pandoc runs), and link any related issues or examples.
- Mention manual verification steps (example Markdown, Pandoc output, etc.) so reviewers know what was exercised.
- When the user requests a detailed commit message, capture those bullet points for them (e.g., drop them into a helper script like `scripts/commit_refactor.sh`) so they can run the commit locally without copy/pasting text, and include any necessary `git add <files>` commands inside the helper to ensure the correct files are staged beforehand.
- When the user asks for a release helper, default to a one-off shell script that simply lists the concrete commands (tests, build, git add/commit/tag, pushes, `gh release create`). No automation logic beyond straight command sequencing.
- For visibility into which assistant produced a set of changes, append a short tag such as `(via Codex / GPT-5)` or `(via Claude Code / Claude-3)` at the end of the commit subject/body; match the actual assistant+model you used.
- Before modifying any files:
  - Briefly summarize what you plan to do
  - Wait for the user to confirm that the plan sounds correct
  - Then proceed (avoid “silent” edits, especially for work that might take a while)

## Release Process

### Automated Release (Minilla-style)
The project uses a Minilla-style release workflow where CHANGELOG.md is the single source of truth for versions:

**Workflow:**
1. **Edit code and add CHANGELOG entry**
   ```markdown
   ## [0.7.4] - 2025-11-26

   ### Added
   - New feature description
   ```
   **Important:**
   - Only edit CHANGELOG.md - do NOT manually update version numbers in pyproject.toml or __init__.py
   - No need to commit CHANGELOG.md before release - it will be included in the release commit automatically

2. **Preview release (dry run)**: `make release-n`
   - Shows all commands without executing them
   - Displays formatted release notes
   - Safe to run anytime

3. **Execute release**: `make release`
   - Performs dirty check (fails if uncommitted changes exist, except CHANGELOG.md)
   - Extracts version from CHANGELOG.md
   - **Automatically updates** `pyproject.toml` and `pandoc_embedz/__init__.py`
   - Updates `uv.lock` with new version
   - Runs all tests: `uv run pytest tests/`
   - Commits ALL tracked changes with `git add -u` (prevents missing files)
   - Creates annotated tag with full release notes
   - Pushes to GitHub
   - Creates GitHub Release using `gh release create --notes-from-tag`
   - **GitHub Actions automatically publishes to PyPI**

**Key Features:**
- **Single source of truth**: CHANGELOG.md controls version
- **Automatic version updates**: No manual editing of version numbers
- **Dirty check**: Prevents releases with uncommitted changes
- **Complete commits**: `git add -u` includes all tracked changes (no more missing files like v0.7.2)
- **Dry run support**: `perl` commands mocked in dry run mode
- **Error handling**: `${VERSION:?...}` ensures version extraction succeeds

**Flags:**
- `IGNORE_DIRTY=1`: Skip dirty check (used by `make release-n`)
- `IGNORE_TAG_EXISTS=1`: Allow existing tags (used by `make release-n`)

### Manual Release (Fallback)
If you need to release manually without the Makefile:
1. **Update version**: Edit `version` in `pyproject.toml` (e.g., `0.3.0` → `0.4.0`)
2. **Update CHANGELOG.md**: Add new version section with Added/Changed/Fixed categories
3. **Run tests**: `uv run pytest tests/` (or `python -m pytest tests/`)
4. **Commit changes**: `git commit -m "Release version X.Y.Z"`
5. **Create tag**: `git tag -a vX.Y.Z -m "Release version X.Y.Z"`
6. **Push**: `git push && git push --tags`
7. **Create GitHub Release**: `gh release create vX.Y.Z --title "vX.Y.Z - Title" --notes "..."`
   - Check workflow status: `gh run list --limit 3`
   - GitHub Actions will build with `uv build` and publish to PyPI

### Post-Release Verification
- **Verify PyPI**: Check that new version appears: `pip index versions pandoc-embedz`
- **Install new version**: Use `pip install --no-cache-dir --upgrade pandoc-embedz` to avoid cache issues
  - Note: `pip install --upgrade` may use cached metadata and not see the new version immediately
  - Alternative: `pip uninstall pandoc-embedz && pip install pandoc-embedz`
  - Or wait a few minutes for pip's cache to expire

## Security & Configuration Tips
- Keep configuration tight: reuse `load_template_from_saved`/`validate_file_path` when reading external data so path traversal checks stay centralized.
- Store any new template snippets or CSV fixtures near the tests that validate them to make review easier.

## Filter Chaining & Code Block Generation

### Generating Code Blocks for Other Filters
embedz can generate code blocks (e.g., ```` ```{.table} ````) that are processed by subsequent filters like pantable:

- **How it works**: `pf.convert_text(result, input_format='markdown')` in `filter.py:743` parses the rendered template output and converts it to Pandoc AST elements, including CodeBlocks
- **Filter order**: Use `--filter pandoc-embedz --filter pantable` to chain filters; embedz runs first and generates code blocks, then pantable processes them
- **Requirements**: The embedz block must have data; blocks without data return empty list `[]` (see `filter.py:722-723`)

### Writing Triple Backticks in Templates

Use four backticks for the outer fence:
`````markdown
````{.embedz format=csv}
---
---
```{.table}
{% for row in data -%}
{{ row.product }},{{ row.sales }}
{% endfor -%}
```
---
product,sales
Widget,100
````
`````

- Use four backticks for the outer fence to write three backticks inside
- Empty YAML header `---` `---` is required (otherwise the inner `---` won't be recognized as data separator)
- This is standard Markdown syntax, no special handling needed

### Data Requirements
- **Inline data must come after the third `---`** (template/data separator)
- **Data in `with:` section is NOT treated as `data`**; it's only available as template variables
- If `data` is empty or `[]`, the filter returns `[]` with no output (by design; templates without data are considered "definitions")
- To iterate over data, use `{% for row in data %}`, not `{% for row in with.products %}`

### Query Template Expansion

SQL queries support Jinja2 template variable expansion, allowing you to share query logic across multiple embedz blocks:

**Define global variables:**
````markdown
```{.embedz}
---
global:
  start_date: '2024-01-01'
  end_date: '2024-12-31'
---
```
````

**Use in queries - Variable interpolation:**
````markdown
```{.embedz data=data.csv}
---
query: SELECT * FROM data WHERE date BETWEEN '{{ global.start_date }}' AND '{{ global.end_date }}'
---
Template here
```
````

**Use in queries - Complete query as variable:**
````markdown
```{.embedz}
---
global:
  period_filter: SELECT * FROM data WHERE date BETWEEN '2024-01-01' AND '2024-12-31'
---
```

```{.embedz data=sales.csv}
---
query: "{{ global.period_filter }}"
---
Template here
```
````

**Nested global variables:**

Global variable values can reference other global variables, enabling complex query composition:

````markdown
```{.embedz}
---
global:
  year: '2024'
  start_date: '{{ global.year }}-01-01'
  end_date: '{{ global.year }}-12-31'
  period_filter: SELECT * FROM data WHERE date BETWEEN '{{ global.start_date }}' AND '{{ global.end_date }}'
---
```
````

Variables are expanded in **definition order** during `GLOBAL_VARS.update()`:
- Each value is checked for `{{` or `{%`
- If found, it's rendered as a Jinja2 template using previously defined global variables
- This allows multi-level nesting (e.g., `year` → `start_date` → `period_filter`)

**Key points:**
- Template expansion occurs **before** data loading, so `global` and `with` variables are available
- Queries containing `{{` or `{%` are automatically processed as Jinja2 templates
- Global variable **values** are also expanded if they contain template syntax
- Variables are processed in definition order (later variables can reference earlier ones)
- The `global.` prefix is optional: `{{ start_date }}` and `{{ global.start_date }}` both work
- The `with.` prefix is also optional for local variables
- Use quotes around queries that start with `{{` to ensure valid YAML
- Works with CSV, TSV, SSV formats (via pandas SQL) and SQLite databases

### Preamble Section and Macro Sharing

The `preamble` section defines document-wide control structures (macros, `{% set %}`, imports) that are available throughout the entire document. All templates are evaluated in a single unified Jinja2 environment.

**Define macros and variables in preamble:**
````markdown
```{.embedz}
---
preamble: |
  {% set fiscal_year = 2024 %}
  {% macro BETWEEN(start, end) -%}
  SELECT * FROM data WHERE date BETWEEN '{{ start }}' AND '{{ end }}'
  {%- endmacro %}
---
```
````

**Use preamble definitions in global variables and queries:**
````markdown
```{.embedz}
---
global:
  start_date: "{{ fiscal_year }}-04-01"
  end_date: "{{ fiscal_year + 1 }}-03-31"
  yearly_query: "{{ BETWEEN(start_date, end_date) }}"
---
```

```{.embedz data=sales.csv}
---
query: "{{ BETWEEN('2024-01-01', '2024-12-31') }}"
---
Template here
```
````

**Alternative: Macros in named templates (auto-shared):**
````markdown
```{.embedz define=sql-macros}
{%- macro BETWEEN(start, end) -%}
SELECT * FROM data WHERE date BETWEEN '{{ start }}' AND '{{ end }}'
{%- endmacro -%}
```
````

Macros defined in named templates are **automatically** added to the global control structures, so no explicit import needed.

**Implementation details:**
- All templates share a single global Jinja2 environment (GLOBAL_ENV)
- `preamble` content is prepended to all template expansions via CONTROL_STRUCTURES_STR
- Macros from named templates are auto-added to CONTROL_STRUCTURES_STR
- Template variables in `global` values are expanded using the unified environment
- Leading newlines from preamble are stripped with `lstrip('\n')`
- The Environment uses `FunctionLoader(load_template_from_saved)` to resolve template names

**Use cases:**
- SQL query builders: Define query macros once, compose complex queries
- Date calculations: Macros for fiscal periods, quarters, date ranges
- Document-wide settings: Title, year, author via `{% set %}`
- Complex transformations: Encapsulate multi-step logic in reusable functions

**Key differences from old approach:**
- Use `preamble` for control structures instead of mixing them in `global` variables
- No need for explicit `{% from 'template' import macro %}` - macros are globally available
- Cleaner separation: `preamble` for control, `global` for data

## Parameter Aliasing

### Overview
The project uses a parameter aliasing system to improve user-facing API clarity while maintaining backward compatibility.

**User-facing parameters for template definition:**
- `define: template-name` - **Recommended** parameter for defining reusable templates
- `name: template-name` - **Deprecated** but still functional for backward compatibility (shows warning)

**User-facing parameters for template usage:**
- `template: template-name` - **Recommended** parameter for YAML (more declarative)
- `as: template-name` - **Alternative** parameter, shorter for attributes (both work without warnings)

**Rationale:**
- `define` vs `template`/`as` makes the distinction between definition and usage clearer
- `name` was ambiguous (definition or reference?)
- `template` is more declarative in YAML, while `as` is shorter for attributes
- Backward compatibility ensures existing users' code continues to work

### Implementation

**Location:** `pandoc_embedz/config.py`

**Key components:**
```python
# Internal canonical name -> Preferred external alias
PARAMETER_PREFERRED_ALIASES = {
    'name': 'define',  # 'define' maps to internal 'name'
    'as': 'template',  # 'template' maps to internal 'as'
}

# Parameters deprecated for direct use
DEPRECATED_DIRECT_USE = {
    'name': 'define',  # Show warning when 'name' is used
    # Note: 'as' is NOT deprecated - both 'as' and 'template' work without warnings
}

def normalize_config(config: Dict[str, Any], warn_deprecated: bool = True) -> Dict[str, Any]:
    """Normalize config by converting preferred aliases to internal names"""
    # 1. Check for conflicts (both 'define' and 'name' specified)
    # 2. Convert 'define' -> 'name' (no warning)
    # 3. Keep 'name' as-is but show deprecation warning
    # 4. Return normalized config with internal names
```

**Integration:**
- Called in `filter.py` after config merging, before validation
- Applied to both filter mode and standalone mode
- Works with YAML headers, attributes, and external config files

**Internal naming:**
- Code uses `config.get('name')` throughout (natural variable name)
- Documentation uses `define` exclusively
- Users can use either, but `define` is recommended

### Adding New Aliases

To add a new parameter alias:

1. **Update `PARAMETER_PREFERRED_ALIASES`:**
   ```python
   PARAMETER_PREFERRED_ALIASES = {
       'name': 'define',
       'source': 'data',  # Example: 'data' as internal name
   }
   ```

2. **Update `DEPRECATED_DIRECT_USE` if needed:**
   ```python
   DEPRECATED_DIRECT_USE = {
       'name': 'define',
       'source': 'data',  # If old name should show warning
   }
   ```

3. **Add tests** in `tests/test_attributes.py`:
   - Test preferred alias works without warning
   - Test deprecated name works with warning
   - Test conflict detection

4. **Update documentation** to use only the preferred alias

### Testing
Tests for parameter aliasing are in `tests/test_attributes.py::TestDeprecatedNameParameter`:
- `test_name_parameter_yaml_still_works` - YAML header with deprecated `name`
- `test_name_attribute_still_works` - Attribute with deprecated `name`
- `test_name_template_is_saved_correctly` - Template saving with deprecated `name`

All tests verify:
1. Deprecated parameter still works
2. Deprecation warning is shown
3. Template is correctly saved/processed
